---

settings:

  cnn:
    kernels: 256
    size: 11
    stride: 2
  rnn:
    size: 256
    depth: 3
  vocab:
    size: 28

model:

  - input: utterance
  - convolution:
      kernels: "{{ cnn.kernels }}"
      size: "{{ cnn.size }}"
      strides: "{{ cnn.stride }}"
      border: valid
  - activation: relu
  - for:
      range: "{{ rnn.depth }}"
      iterate:
        - recurrent:
            size: "{{ rnn.size }}"
            sequence: yes
  - parallel:
      apply:
        - dense: "{{ vocab.size + 1 }}"
  - activation: softmax
  - output: asr

train:

  data:
    # This will produce:
    # - utterance
    # - utterance_length
    # - transcript
    # - transcript_length
    # - duration
    - speech_recognition:
        url: "http://kur.deepgram.com/data/librispeech-dev-clean.tar.gz"
        checksum: 32f2c7e62299bd2abb401fdc320e4f03374b4c5ba0a3d391330adaf277be30cc
        path: "~/kur"
        type: spec
        max_duration: 10

  provider:
    batch_size: 16
    sortagrad: duration

  optimizer:
    name: sgd
    nesterov: yes
    learning_rate: 1e-4
    momentum: 0.9
    clip:
      norm: 1

loss:
  - name: ctc
    # The model's output (its best-guest transcript).
    target: asr
    # How long the corresponding audio utterance is.
    input_length: utterance_length
    relative_to: utterance
    # How long the ground-truth transcript is.
    output_length: transcript_length
    # The ground-truth transcipt itself.
    output: transcript
